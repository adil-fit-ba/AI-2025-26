# Softverski Inteligentni Agenti

> **Edukativni projekat koji demonstrira univerzalnu arhitekturu inteligentnih agenata kroz razliÄite tipove implementacija**

[![.NET](https://img.shields.io/badge/.NET-8.0-512BD4?logo=dotnet)](https://dotnet.microsoft.com/)
[![C#](https://img.shields.io/badge/C%23-12.0-239120?logo=csharp)](https://docs.microsoft.com/en-us/dotnet/csharp/)
[![License](https://img.shields.io/badge/License-Educational-blue.svg)]()

---

## ğŸ“– SadrÅ¾aj

- [O Projektu](#-o-projektu)
- [KljuÄni Koncepti](#-kljuÄni-koncepti)
- [Arhitektura](#-arhitektura)
- [Primjeri Agenata](#-primjeri-agenata)
- [Instalacija i Pokretanje](#-instalacija-i-pokretanje)
- [Struktura Projekta](#-struktura-projekta)
- [PedagoÅ¡ki Ciljevi](#-pedagoÅ¡ki-ciljevi)
- [TehniÄki Detalji](#-tehniÄki-detalji)

---

## ğŸ¯ O Projektu

Ovaj projekat demonstrira **UNIVERZALNU arhitekturu softverskih inteligentnih agenata** kroz implementaciju Å¡est razliÄitih tipova agenata koji svi dijele istu osnovnu strukturu.

### Motivacija

U AI literaturi postoji mnogo razliÄitih pristupa implementaciji inteligentnih agenata. Ovaj projekat pokazuje da **svi agenti, bez obzira na tip, dijele istu fundamentalnu arhitekturu**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERCEPCIJA â”‚ â”€â”€â–º â”‚   POLITIKA  â”‚ â”€â”€â–º â”‚   AKTUATOR  â”‚
â”‚   (Sense)   â”‚     â”‚   (Think)   â”‚     â”‚    (Act)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â–²                   â”‚
       â”‚                   â”‚                   â”‚
       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   UÄŒENJE    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  (Learn)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### KljuÄna Ideja

**Razlika izmeÄ‘u tipova agenata je SAMO u implementaciji komponenti, ne u arhitekturi!**

- Rule-Based agent â†’ IF-THEN pravila
- Supervised Learning agent â†’ ML model
- Reinforcement Learning agent â†’ Q-Learning
- Human-in-the-Loop agent â†’ feedback od korisnika
- LLM-Powered agent â†’ Large Language Model
- Q-Learning Vacuum Cleaner â†’ kompletan RL primjer sa vizualizacijom

---

## ğŸ”‘ KljuÄni Koncepti

### Inteligentni Agent

Softverski sistem koji:
- âœ… **OpaÅ¾a** okolinu (percepcija)
- âœ… **Donosi odluke** (politika)
- âœ… **UtiÄe** na okolinu (akcija)
- âœ… **UÄi** iz iskustva (uÄenje)

### ÄŒetiri Osnovna Interfejsa

#### 1. `IPerceptionSource<TPercept>`
```csharp
public interface IPerceptionSource<TPercept>
{
    TPercept Observe();
}
```
**Odgovornost:** OmoguÄ‡ava agentu da "vidi" okolinu.

**Primjeri:**
- Senzor temperature
- Email inbox
- Stanje grid mreÅ¾e
- Ticket queue

#### 2. `IPolicy<TPercept, TAction>`
```csharp
public interface IPolicy<TPercept, TAction>
{
    TAction SelectAction(TPercept percept);
}
```
**Odgovornost:** "Mozak" agenta - odluÄuje Å¡ta uraditi.

**Primjeri:**
- IF-THEN pravila
- Q-tabela
- ML model
- LLM prompt

#### 3. `IActuator<TAction, TResult>`
```csharp
public interface IActuator<TAction, TResult>
{
    TResult Execute(TAction action);
}
```
**Odgovornost:** IzvrÅ¡ava akciju i vraÄ‡a rezultat.

**Primjeri:**
- Upravljanje ureÄ‘ajem
- Pomjeranje robota
- Slanje odgovora korisniku
- ÄŒiÅ¡Ä‡enje tile-a

#### 4. `ILearningComponent<TExperience>` (opciono)
```csharp
public interface ILearningComponent<TExperience>
{
    void Learn(TExperience experience);
}
```
**Odgovornost:** PoboljÅ¡ava ponaÅ¡anje agenta kroz vrijeme.

**Primjeri:**
- Q-Learning algoritam
- AÅ¾uriranje modela
- PrilagoÄ‘avanje parametara
- UÄenje iz feedbacka

---

## ğŸ—ï¸ Arhitektura

### GeneriÄki Agent

Svaki agent je instanca `SoftwareAgent<TPercept, TAction, TResult, TExperience>`:

```csharp
public class SoftwareAgent<TPercept, TAction, TResult, TExperience> : IAgent
{
    public virtual void Step()
    {
        // 1. SENSE  â†’ Prikupi informacije iz okoline
        var percept = _perception.Observe();

        // 2. THINK  â†’ OdluÄi Å¡ta uraditi
        var action = _policy.SelectAction(percept);

        // 3. ACT    â†’ IzvrÅ¡i akciju, dobij rezultat
        var result = _actuator.Execute(action);

        // 4. LEARN  â†’ PoboljÅ¡aj se na osnovu iskustva
        if (_learner != null && _experienceBuilder != null)
        {
            var experience = _experienceBuilder(percept, action, result);
            _learner.Learn(experience);
        }
    }
}
```

### Sense â†’ Think â†’ Act â†’ Learn Ciklus

Svaki poziv `agent.Step()` prolazi kroz Äetiri faze:

1. **SENSE** - Agent opaÅ¾a trenutno stanje okoline
2. **THINK** - Agent odluÄuje koju akciju preduzeti
3. **ACT** - Agent izvrÅ¡ava akciju i dobija odgovor od okoline
4. **LEARN** - Agent koristi iskustvo da poboljÅ¡a buduÄ‡e odluke

---

## ğŸ¤– Primjeri Agenata

### A. Rule-Based Agent (Termostat)

**Tip:** Reaktivni agent bez uÄenja  
**Politika:** IF-THEN pravila  
**Cilj:** OdrÅ¾avanje temperature

```
ğŸ“Š Komponente:
  â€¢ TPercept    = TemperatureReading (temperatura u Â°C)
  â€¢ TAction     = ThermostatAction {HeatOn, HeatOff, CoolOn, CoolOff}
  â€¢ TResult     = bool (uspjeÅ¡nost izvrÅ¡enja)
  â€¢ TExperience = N/A (ne uÄi)

ğŸ’¡ Karakteristike:
  âœ“ DeterministiÄka pravila
  âœ“ Nema uÄenje
  âœ“ Brzo i pouzdano
  âœ— Ne prilagoÄ‘ava se
```

**UÄenje:** Nema - pravila su fiksna

---

### B. Supervised Learning Agent (Spam Detektor)

**Tip:** Agent sa nadgledanim uÄenjem  
**Politika:** NauÄeni ML model  
**Cilj:** Klasifikacija email poruka

```
ğŸ“Š Komponente:
  â€¢ TPercept    = EmailFeatures (subject, links, suspicious words)
  â€¢ TAction     = EmailClass {NotSpam, Spam}
  â€¢ TResult     = EmailClass (taÄna labela)
  â€¢ TExperience = SupervisedExperience (predicted vs actual)

ğŸ’¡ Karakteristike:
  âœ“ UÄi iz labeliranih primjera
  âœ“ DynamicPerception (inbox queue)
  âœ“ Kontinuirano procesiranje
  âœ“ PrilagoÄ‘ava se novim podacima
```

**UÄenje:** AÅ¾urira model na osnovu razlike izmeÄ‘u predviÄ‘ene i stvarne labele

**KljuÄna Tehnika:** `DynamicPerception` omoguÄ‡ava agentu da procesira email-ove u toku (stream), ne kao batch.

---

### C. Reinforcement Learning Agent (Robot)

**Tip:** RL agent sa Q-Learning algoritmom  
**Politika:** Q-tabela sa epsilon-greedy strategijom  
**Cilj:** StiÄ‡i do pozicije 5 na traci

```
ğŸ“Š Komponente:
  â€¢ TPercept    = RobotState (pozicija [0..5])
  â€¢ TAction     = RobotAction {Left, Right}
  â€¢ TResult     = RLStepResult (novo stanje, nagrada)
  â€¢ TExperience = RLExperience (state, action, reward, nextState)

ğŸ’¡ Karakteristike:
  âœ“ UÄi iz nagrada
  âœ“ Epsilon-greedy eksploracija
  âœ“ Goal-oriented ponaÅ¡anje
  âœ“ Q-Learning: Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') âˆ’ Q(s,a)]
```

**UÄenje:** Q-Learning algoritam aÅ¾urira vrijednosti stanja-akcija parova

**Q-Learning Formula:**
```
Q(s,a) â† Q(s,a) + Î± [ r + Î³ max Q(s',a') âˆ’ Q(s,a) ]

gdje:
  â€¢ Î± (alpha) = stopa uÄenja (learning rate)
  â€¢ Î³ (gamma) = faktor diskontiranja (discount factor)
  â€¢ r         = nagrada (reward)
```

---

### D. Human-in-the-Loop Agent (Preporuka filmova)

**Tip:** Agent koji uÄi iz ljudskog feedbacka  
**Politika:** Model koji se prilagoÄ‘ava preferencama  
**Cilj:** Davanje personalizovanih preporuka

```
ğŸ“Š Komponente:
  â€¢ TPercept    = UserQuery (Å¾anr, mood)
  â€¢ TAction     = MovieRecommendation
  â€¢ TResult     = UserFeedback (ocjena 1-5)
  â€¢ TExperience = FeedbackExperience (akcija + ocjena)

ğŸ’¡ Karakteristike:
  âœ“ UÄenje iz ljudskog feedbacka
  âœ“ DynamicPerception (ticket queue)
  âœ“ Personalizacija kroz vrijeme
  âœ“ Interaktivno poboljÅ¡anje
```

**UÄenje:** PoveÄ‡ava vjerovatnoÄ‡u uspjeÅ¡nih preporuka na osnovu ocjena korisnika

---

### E. LLM-Powered Agent (KorisniÄka podrÅ¡ka)

**Tip:** Agent zasnovan na jeziÄkom modelu  
**Politika:** Large Language Model (simuliran)  
**Cilj:** RjeÅ¡avanje korisniÄkih upita

```
ğŸ“Š Komponente:
  â€¢ TPercept    = SupportTicket (tekst upita)
  â€¢ TAction     = SupportResponse (odgovor, tip)
  â€¢ TResult     = SupervisorDecision (prihvati/odbaci/eskalacija)
  â€¢ TExperience = SupervisedExperience (response + decision)

ğŸ’¡ Karakteristike:
  âœ“ Kontekstualno razumijevanje
  âœ“ Generisanje prirodnog jezika
  âœ“ Supervizija i eskalacija
  âœ“ DynamicPerception (ticket queue)
  âœ“ Simulacija LLM-a (demonstracijski primjer)
```

**UÄenje:** UÄenje iz supervizorskih odluka (prihvatanje/odbijanje odgovora)

**Arhitektura:**
- **Ticket Queue** - Simulirani stream korisniÄkih upita
- **LLM Policy** - Generisanje odgovora
- **Supervisor** - Kontrola kvaliteta
- **Learner** - PrilagoÄ‘avanje na osnovu feedbacka

---

### F. Q-Learning Vacuum Cleaner

**Tip:** Kompletan RL agent sa vizualizacijom  
**Politika:** Q-Learning na grid mreÅ¾i  
**Cilj:** OÄistiti sve prljave ploÄice u gridu

```
ğŸ“Š Komponente:
  â€¢ TPercept    = VacuumState (pozicija, status grid-a)
  â€¢ TAction     = VacuumAction {Up, Down, Left, Right, Suck}
  â€¢ TResult     = VacuumStepResult (novo stanje, nagrada)
  â€¢ TExperience = VacuumExperience (SARSA tuple)

ğŸ’¡ Karakteristike:
  âœ“ 2D grid world
  âœ“ Kompleksna prostorna navigacija
  âœ“ 5 akcija (4 smjera + Suck)
  âœ“ Vizualizacija grid-a i Q-vrijednosti
  âœ“ NasljeÄ‘uje SoftwareAgent (pokazuje ekstenzibilnost)
```

**Grid Okolina:**
```
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ A â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚ âˆ™ â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

Legenda:
  A = Agent (Vacuum Cleaner)
  âˆ™ = Clean (Äisto)
  â–‘ = Dirty (prljavo)
```

**UÄenje:** Q-Learning na svim kombinacijama stanja (pozicija + status ploÄica)

**SpecifiÄnosti:**
- NasljeÄ‘uje `SoftwareAgent` - demonstrira kako se osnovna arhitektura moÅ¾e ekstendovati
- PrilagoÄ‘ena `Step()` metoda sa vizualizacijom
- Dodati metodi za prikaz grid-a i Q-vrijednosti

---

## ğŸš€ Instalacija i Pokretanje

### Preduvjeti

- **.NET 8.0 SDK** ili noviji
- IDE: Visual Studio, Rider, ili VS Code sa C# ekstenzijom

### Kloniranje Projekta

```bash
git clone <repository-url>
cd AI-Agents
```

### Kompajliranje

```bash
dotnet build
```

### Pokretanje

```bash
dotnet run
```

### Interaktivni Meni

Nakon pokretanja, vidjet Ä‡ete meni sa opcijama:

```
+===============================================================+
|     DEMONSTRACIJA TIPOVA SOFTVERSKIH AGENATA                  |
+===============================================================+
|  Svi koriste ISTE INTERFEJSE, razlicite implementacije!       |
+===============================================================+

  Odaberite primjer:

  [A] PRIMJER A: Rule-Based Agent (Termostat)
  [B] PRIMJER B: Supervised Learning Agent (Spam Detektor)
  [C] PRIMJER C: Reinforcement Learning Agent (Robot)
  [D] PRIMJER D: Human-in-the-Loop Agent (Preporuka filmova)
  [E] PRIMJER E: LLM-Powered Agent (KorisniÄka podrÅ¡ka)
  [F] PRIMJER F: Q-Learning Vacuum Cleaner
  [7] Pokreni SVE primjere redom (osim Vacuum Cleaner-a)
  [Q] Izlaz

  VaÅ¡ izbor:
```

---

## ğŸ“ Struktura Projekta

```
AI-Agents/
â”‚
â”œâ”€â”€ SharedCore.cs                           # Osnovna arhitektura
â”‚   â”œâ”€â”€ IPerceptionSource<T>                # Interface za percepciju
â”‚   â”œâ”€â”€ IPolicy<TPercept, TAction>          # Interface za politiku
â”‚   â”œâ”€â”€ IActuator<TAction, TResult>         # Interface za aktuator
â”‚   â”œâ”€â”€ ILearningComponent<TExperience>     # Interface za uÄenje
â”‚   â”œâ”€â”€ IAgent                              # Interface za agenta
â”‚   â”œâ”€â”€ SoftwareAgent<...>                  # GeneriÄka implementacija
â”‚   â”œâ”€â”€ StaticPerception<T>                 # Fiksna percepcija
â”‚   â”œâ”€â”€ DynamicPerception<T>                # DinamiÄka percepcija
â”‚   â””â”€â”€ ConsoleActuator<T>                  # Jednostavna akcija
â”‚
â”œâ”€â”€ ExampleA_RuleBasedAgent.cs              # Termostat (IF-THEN pravila)
â”‚   â”œâ”€â”€ TemperatureReading                  # Percepcija temperature
â”‚   â”œâ”€â”€ ThermostatAction                    # Akcije termostata
â”‚   â”œâ”€â”€ ThermostatPolicy                    # Pravila odluÄivanja
â”‚   â””â”€â”€ TemperatureSensor                   # Simulirani senzor
â”‚
â”œâ”€â”€ ExampleB_SupervisedLearningAgent.cs     # Spam detektor
â”‚   â”œâ”€â”€ EmailFeatures                       # Feature reprezentacija
â”‚   â”œâ”€â”€ EmailClass                          # Spam/NotSpam
â”‚   â”œâ”€â”€ SpamClassifierPolicy                # ML model
â”‚   â”œâ”€â”€ DynamicSpamOracle                   # Oracle za labele
â”‚   â””â”€â”€ SupervisedLearner                   # UÄenje iz labela
â”‚
â”œâ”€â”€ ExampleC_ReinforcementLearningAgent.cs  # Robot na traci
â”‚   â”œâ”€â”€ RobotState                          # Pozicija robota
â”‚   â”œâ”€â”€ RobotAction                         # Left/Right
â”‚   â”œâ”€â”€ RobotEnvironment                    # 1D traka
â”‚   â”œâ”€â”€ SimpleQPolicy                       # Q-tabela + epsilon-greedy
â”‚   â””â”€â”€ QLearner                            # Q-Learning algoritam
â”‚
â”œâ”€â”€ ExampleD_HumanInLoopAgent.cs            # Preporuka filmova
â”‚   â”œâ”€â”€ UserQuery                           # Upit korisnika
â”‚   â”œâ”€â”€ MovieRecommendation                 # Preporuka filma
â”‚   â”œâ”€â”€ MovieRecommenderPolicy              # Model preporuka
â”‚   â”œâ”€â”€ UserFeedbackOracle                  # Ocjene korisnika
â”‚   â””â”€â”€ FeedbackLearner                     # UÄenje iz ocjena
â”‚
â”œâ”€â”€ ExampleE_LLMPoweredAgent.cs             # KorisniÄka podrÅ¡ka
â”‚   â”œâ”€â”€ SupportTicket                       # Ticket sa upitom
â”‚   â”œâ”€â”€ SupportResponse                     # Odgovor agenta
â”‚   â”œâ”€â”€ LLMPolicy                           # Simulirani LLM
â”‚   â”œâ”€â”€ QualitySupervisor                   # Supervizor kvaliteta
â”‚   â””â”€â”€ SupervisedLearner                   # UÄenje iz supervizije
â”‚
â”œâ”€â”€ ExampleF_VacuumCleaner.cs               # Q-Learning Vacuum
â”‚   â”œâ”€â”€ VacuumState                         # Pozicija + grid status
â”‚   â”œâ”€â”€ VacuumAction                        # Up/Down/Left/Right/Suck
â”‚   â”œâ”€â”€ VacuumEnvironment                   # 2D grid world
â”‚   â”œâ”€â”€ VacuumQPolicy                       # Q-Learning politika
â”‚   â”œâ”€â”€ VacuumQLearner                      # Q-Learning updater
â”‚   â””â”€â”€ VacuumAgent : SoftwareAgent         # Ekstenzija osnovnog agenta
â”‚
â”œâ”€â”€ Program.cs                              # Glavni program + meni
â”‚
â””â”€â”€ README.md                               # Dokumentacija (ovaj fajl)
```

---

## ğŸ“ PedagoÅ¡ki Ciljevi

### 1. Univerzalnost Arhitekture

**Cilj:** Studenti shvataju da svi inteligentni agenti dijele istu strukturu.

**Metoda:** Å est razliÄitih tipova agenata, svi koriste iste interfejse.

**Ishod:** Razumijevanje da razlika nije u arhitekturi, veÄ‡ u implementaciji komponenti.

---

### 2. Razlika: Agent vs. Algoritam

**Problem:** Studenti Äesto brka ML algoritme sa agentima.

**RjeÅ¡enje:** 
- **Algoritam** = funkcija koja se pozove jednom
- **Agent** = proces koji kontinuirano opaÅ¾a, odluÄuje i uÄi

**Primjer:** Spam detektor sa `DynamicPerception` - agent procesira stream emailova, ne batch dataset.

---

### 3. Percepcija: Static vs. Dynamic

**Static Perception:**
```csharp
var perception = new StaticPerception<int>(42);
// Uvijek vraÄ‡a 42
```

**Dynamic Perception:**
```csharp
var queue = new Queue<Email>();
var perception = new DynamicPerception<Email>(() => queue.Dequeue());
// Svaki put vraÄ‡a NOVI email iz queue-a
```

**Cilj:** Razumijevanje da agenti rade sa PROMJENLJIVOM okolinom.

---

### 4. Shared State Pattern

**Problem:** Kako percepcija i oracle dijele istu informaciju?

**Primjer iz Spam Detektora:**
```csharp
(EmailFeatures email, EmailClass label) currentEmail = default;

var perception = new DynamicPerception<EmailFeatures>(() => {
    currentEmail = inboxQueue.Dequeue();
    return currentEmail.email;
});

var oracle = new DynamicSpamOracle(() => currentEmail.label);
```

**Cilj:** Razumijevanje sinhronizacije izmeÄ‘u komponenti agenta.

---

### 5. Goal-Oriented vs. Continuous Agents

**Goal-Oriented:**
- Robot (stiÄ‡i do pozicije 5)
- Vacuum Cleaner (oÄistiti sve ploÄice)

```csharp
for (int step = 0; step < maxSteps && !agent.IsGoalReached; step++)
{
    agent.Step();
}
```

**Continuous:**
- Termostat (radi beskonaÄno)
- Spam detektor (procesira sve emailove)

```csharp
while (true)
{
    agent.Step();
}
```

---

### 6. Ekstenzibilnost: NasljeÄ‘ivanje

**Primjer:** `VacuumAgent` nasljeÄ‘uje `SoftwareAgent`

```csharp
public sealed class VacuumAgent : SoftwareAgent<VacuumState, VacuumAction, VacuumStepResult, VacuumExperience>
{
    public override void Step()
    {
        base.Step();           // Poziva originalni ciklus
        RenderGrid();          // Dodaje vizualizaciju
    }
}
```

**Cilj:** Pokazuje kako se osnovna arhitektura moÅ¾e prilagoditi bez mijenjanja core logike.

---

## ğŸ”§ TehniÄki Detalji

### Generic Type Parameters

Svaki agent je parametrizovan sa Äetiri tipa:

```csharp
SoftwareAgent<TPercept, TAction, TResult, TExperience>
```

| Parametar | Opis | Primjer |
|-----------|------|---------|
| `TPercept` | Å ta agent vidi | `TemperatureReading`, `EmailFeatures` |
| `TAction` | Å ta agent moÅ¾e uraditi | `ThermostatAction`, `RobotAction` |
| `TResult` | Å ta okolina vraÄ‡a | `bool`, `RLStepResult` |
| `TExperience` | Iskustvo za uÄenje | `RLExperience`, `SupervisedExperience` |

---

### Dependency Injection Pattern

Agenti koriste constructor injection:

```csharp
var agent = new SoftwareAgent<...>(
    perception: senzor,
    policy: mozak,
    actuator: izvrÅ¡ilac,
    experienceBuilder: eksperiencija,
    learner: uÄenje,
    goalChecker: cilj
);
```

**Prednosti:**
- âœ… Testabilnost (lako mock-ovati komponente)
- âœ… Fleksibilnost (zamjena implementacija)
- âœ… Modularnost (nezavisne komponente)

---

### Optional Components

UÄenje i goal checker su **opcioni**:

```csharp
// Agent BEZ uÄenja (Rule-Based)
var agent = new SoftwareAgent<...>(
    perception: sensor,
    policy: policy,
    actuator: actuator
    // learner: null (implicitno)
    // goalChecker: null (implicitno)
);

// Agent SA uÄenjem (RL)
var agent = new SoftwareAgent<...>(
    perception: env,
    policy: qPolicy,
    actuator: env,
    experienceBuilder: (s, a, r) => new Experience(s, a, r),
    learner: qLearner,
    goalChecker: () => env.IsAtGoal
);
```

---

### Record Structs

Projekat koristi `readonly record struct` za podatke:

```csharp
public readonly record struct RobotState(int Position);
```

**Prednosti:**
- âœ… Value semantics (kopiranje po vrijednosti)
- âœ… Immutability (ne moÅ¾e se mijenjati)
- âœ… Automatic equality (strukturna jednakost)
- âœ… Performance (stack allocation)

---

### Enum za Akcije

KoriÅ¡tenje enumeracija umjesto integer konstanti:

```csharp
public enum RobotAction { Left, Right }
```

**Prednosti:**
- âœ… Type safety (kompajler provjerava)
- âœ… ÄŒitljivost (samoobjaÅ¡njavajuÄ‡e)
- âœ… IntelliSense podrÅ¡ka

---

## ğŸ“Š PoreÄ‘enje Agenata

| Agent | Politika | UÄenje | Percepcija | Goal | SloÅ¾enost |
|-------|----------|--------|------------|------|-----------|
| **Termostat** | IF-THEN | âŒ | Dynamic | âŒ | â­ |
| **Spam Detektor** | ML Model | âœ… | Dynamic Queue | âŒ | â­â­ |
| **Robot** | Q-Learning | âœ… | Static | âœ… | â­â­ |
| **Movie Recommender** | Feedback Model | âœ… | Dynamic Queue | âŒ | â­â­â­ |
| **Customer Support** | LLM (sim.) | âœ… | Dynamic Queue | âŒ | â­â­â­â­ |
| **Vacuum Cleaner** | Q-Learning Grid | âœ… | 2D Grid | âœ… | â­â­â­â­â­ |

---

## ğŸ¯ KljuÄne Lekcije

### 1. **Arhitektura > Implementacija**
Svi agenti koriste istu arhitekturu. Razlika je samo u tome **kako** su komponente implementirane.

### 2. **Agent â‰  Algoritam**
Agent je proces koji kontinuirano opaÅ¾a i reaguje. Algoritam je funkcija koja se pozove jednom.

### 3. **UÄenje je Opciono**
Ne svi agenti moraju uÄiti. Rule-based agenti mogu biti vrlo korisni bez uÄenja.

### 4. **Percepcija je DinamiÄka**
U realnim sistemima, percepcija se mijenja. `DynamicPerception` je kljuÄna za modelovanje takvih sistema.

### 5. **Shared State je Realan Pattern**
Komponente agenta Äesto dijele istu informaciju o okolini. Ovo nije bug - to je feature.

### 6. **Ekstenzibilnost kroz NasljeÄ‘ivanje**
Osnovna arhitektura se moÅ¾e ekstendovati (Vacuum Cleaner primjer) bez mijenjanja core logike.

---

## ğŸ”® Dalja ProÅ¡irenja

MoguÄ‡i pravci za proÅ¡irenje projekta:

### 1. Multi-Agent Sistemi
```csharp
public class MultiAgentEnvironment<TState>
{
    private List<IAgent> _agents;
    
    public void Step()
    {
        foreach (var agent in _agents)
        {
            agent.Step();
        }
    }
}
```

### 2. Asinkroni Agenti
```csharp
public interface IAsyncAgent
{
    Task StepAsync();
}
```

### 3. Neural Network Policies
```csharp
public class NeuralNetworkPolicy : IPolicy<Vector, int>
{
    private readonly IModel _model;
    
    public int SelectAction(Vector state)
    {
        return _model.Predict(state);
    }
}
```

### 4. Komunikacija IzmeÄ‘u Agenata
```csharp
public interface IMessageBroker<TMessage>
{
    void Send(TMessage message);
    TMessage? Receive();
}
```
